%______________________________________________________________________
%   Notes to authors
% Please disable your editor's auto newline wrapping feature.  
% Please format \itemize sections 
%______________________________________________________________________



\chapter{Uda Management } \label{Chapter:UDA}
Uintah offers a number of tools for managing Uintah Data Archives (``UDAs''). These tools are especially useful for large simulations with large output.  These tools are used for quickly moving data, reducing the size and number of variables within your UDA and combining multiple UDAs. 

\iffalse
%______________________________________________________________________
\section{ReduceUda}
The typical mode of operation with production runs is to save all the variables you think you'll ever want to analyze, run the series of simulations, look at the data and then sit on the udas until you're forced to move them or delete them.  To help manage the size of the udas there's a new component(reduce\_uda) that allows users to prune out variables from an existing udas.   This component takes your existing uda,reads the input.xml file, and outputs the modified set of variables to a new uda, leaving the original uda untouched.
Below are instructions:
\begin{enumerate}
\item In the input.xml file set the simulation component type to ``reduce\_uda'', 

$<$SimulationComponent type=``reduce\_uda''/$>$
\item To avoid confusion with the original directory  change the uda name
   $<$filebase$>$UDA-diet.uda$<$/filebase$>$

\item Modify the DataArchiver section to restrict the data that will be saved.  Below are the available options:
   \begin{itemize}
     \item Resave the variables as floats using $<$outputDoubleAsFloat/$>$
     \item Remove variables from an uda by commenting them out
     \item For each variable limit the materials that are saved by using the 
    
     ``material=X'' option in the save label spec.
     \item For each variable limit the levels that it is saved on by using ``levels=X'' option in the save labels spec.
  \end{itemize}
For example to convert all of the doubles variables to floats and limit the variable vel\_CC to be
saved for material 1 make the following changes:

$<$outputDoubleAsFloat/$>$

$<$save label=``vel\_CC'' material=``1''/$>$


\item run the following command.

    mpirun -np X sus -reduce\_uda $<$name of uda directory$>$
    
    This will produce a new uda directory with the pruned variables. All time steps and checkpoints will be copied along with the index.xml, input file, input.xml and .dat files.

\end{enumerate}

When using this tool please be aware of the following:
\begin{itemize}
   \item If you're using this on a machine with a reduced set of system calls (tukey) configure with
          (- -with-boost)  This will enable the boost copy functions.
    \item Reduce\_uda will not work on ALCF machines (expect tukey)
    \item You must manually copy all On-the-Fly files/directories from the original uda
to the new uda, reduce\_uda ignores them.
    \item The $<$outputInterval$>$, $<$outputTimestepInterval$>$ tags are ignored and every
      timestep in the original uda is processed.  If you want to prune timesteps
      you must manually delete timesteps directories and modify the index.xml file.
    \item Use a different uda name for the modifed uda to prevent confusion with the original uda.
    \item In the timestep.xml files the following non-essential entries will be changed:
    
           numProcs:      Number of procs used during the reduceUda run.
           
           oldDelt:       Difference in timesteps, i.e., time(TS) - time (TS-1), in physical time.
           
           proc:          The processor to patch assignment.
    \item The number of files inside of a timestep directory will now equal the number of processors used to reduce the uda.
        You should use the same number of processors to reduce the uda as you will use to visualize it.
         For large runs this should speed up data transfers and post processing utilities.

    \item Checkpoint directories are copied with system calls from the original -$>$ modified uda.
      Only 1 processor is used during the copy so this will be slow for large checkpoints directories.
      Consider moving this manually.
    \item ALWAYS, ALWAYS, ALWAYS verify that the new (modified) uda is consistent
      with your specfications before deleting the original uda.
 \end{itemize}
\fi
%______________________________________________________________________
\section{pscp2}
pscp2 is a tool to quickly transfer data in parallel between two machines. In order for this to work there must be an password-less connection between the two machines. pscp2 is located in /src/scripts/udaTransferScripts/
\\
The usage is 
\begin{Verbatim}[fontsize=\footnotesize]
 ./pscp2 <# processors> 
         <transfer entire uda (y/n)> 
         <remove remote directory (y/n)> 
         < name of local directory> 
         <login@remote machine>:<remote path>
\end{Verbatim}

The following example shows the usage of pscp2 for transferring 1.uda.000 from the local machine to the home directory on ember using 8 processors. It will remove any files in the home directory on ember with the same title of 1.uda.000 but the original copy on the local machine will not be removed.

\begin{Verbatim}
 ./pscp2 8 y n 1.uda.000 username@ember.chpc.utah.edu:/home/
\end{Verbatim}

%______________________________________________________________________
\section{Make Master Uda}
makeMasterUda\_index.csh is a script used to combine multiple udas. This is useful when a simulation must be restarted multiple times and post processing is required. Instead of having to do post processing on each individual uda, makeMasterUda\_index.csh will combine all of the udas to allow for continuous analysis of the simulation start to finish.  The script is located at: src/scripts/makeMasterUda\_index.csh and it depends on the helper script: src/scripts/makeCombinedIndex.sh. The original udas must not be moved or the  masterUda will not find the udas. No changes will be made to the original udas.
\\
The usage is 
\begin{enumerate}
\item mkdir $<$masterUda$>$ This is where all of the udas will be linked together
\item cd $<$masterUda$>$
\item makeMasterUda\_index.csh ../uda.000 ../uda.001 ../uda.00N
\end{enumerate}

%______________________________________________________________________
\section{pTarUda}
pTarUda is a tool used to create/extract compressed tar files of each timestep in a UDA, including the checkpoints directory. pTarUda was designed to run in parallel and works well on udas with a large number of files and/or uncompressed data.  What it will buy you is faster moves, copies and transfers since the OS doesn't have to process as many files.  For uncompressed UDAs you may see up to a 30\% reduction in size. The original timestep directories are not deleted unless the -deleteOrgTimesteps option is used. This tool is found in /src/scripts/udaTransferScripts.
\\
Usage:
\begin{Verbatim}[fontsize=\footnotesize]
pTarUda -<create/extract> -uda <UDA directory name>

  Options:
  -np <int>:                 Number of processors. Default is 10                           
  -allTimesteps <y/n>:       Operate on all directories in uda? Default is yes.            
                             If "n" then a vi window will open allowing you                
                             to edit a list of timesteps to archive/extract.               
  -deleteOrgTimesteps        Delete original timestep directories after they have          
                             been tarred/untarred.                                         
  -continueTarring:          Continue tarring/untarring if previous attempts failed        
  -help:                     Display options summary                                       
\end{Verbatim}
\normalsize


